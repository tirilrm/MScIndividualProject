{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create embeddings for semantic clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node embedding algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load triplets\n",
    "with open('../Method:Knowledge_Graphs/data/triplets_no_cutoff/graphs.json') as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "def embed_nodes(results, with_tag=True):\n",
    "    print(f\"Embedding nodes for with_tag={with_tag}\")\n",
    "    tags_dict = {\n",
    "        'ORG': 0,\n",
    "        'LOC': 1,\n",
    "        'PER': 2,\n",
    "        'MISC': 3\n",
    "    }\n",
    "\n",
    "    # Append all entities\n",
    "    data = {}\n",
    "    for root, triplets in results.items():\n",
    "        nodes = []\n",
    "        for triplet in triplets:\n",
    "            head_tag = tags_dict.get(triplet[1], -1)\n",
    "            tail_tag = tags_dict.get(triplet[3], -1)\n",
    "            head = (triplet[0], head_tag)\n",
    "            tail = (triplet[2], tail_tag)\n",
    "            nodes.append(head)\n",
    "            nodes.append(tail)\n",
    "        data[root] = nodes\n",
    "\n",
    "    # Embed entities\n",
    "    nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "    data_emb = {}\n",
    "    for root, triplets in data.items():\n",
    "        triplets_emb = []\n",
    "        for triplet in triplets:\n",
    "            name = triplet[0]\n",
    "            tag = triplet[1] if with_tag else None\n",
    "\n",
    "            name_emb = nlp(name).vector # Convert to (300,1) dim embedding\n",
    "\n",
    "            if with_tag:\n",
    "                full_emb = np.concatenate([name_emb, np.array([tag])])\n",
    "            else:\n",
    "                full_emb = name_emb\n",
    "            \n",
    "            triplets_emb.append(full_emb)\n",
    "        data_emb[root] = np.array(triplets_emb)\n",
    "\n",
    "    tag_part = 'with_tags' if with_tag else 'no_tags'\n",
    "    filename = f\"data/node_embeddings_{tag_part}.npz\"\n",
    "\n",
    "    print(f'Saving node embeddings to {filename}')\n",
    "    np.savez(filename, **data_emb)\n",
    "\n",
    "##############################\n",
    "for with_tag in [True, False]:\n",
    "    embed_nodes(results, with_tag) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get different aggregate embedding statistics for use later\n",
    "def make_node_clustering_input(with_tags):\n",
    "    data_emb = np.load(f'data/node_embeddings_{with_tags}_tags.npz')\n",
    "\n",
    "    functions = {\n",
    "        'min': np.min,\n",
    "        'max': np.max,\n",
    "        'mean': np.mean,\n",
    "        'median': np.median\n",
    "    }\n",
    "    stats = {func_name: {} for func_name in functions}\n",
    "\n",
    "    length = None\n",
    "\n",
    "    for root, embeddings in data_emb.items():\n",
    "        if embeddings.size == 0:\n",
    "            # print(f\"Warning: Company {root} has no embeddings.\")\n",
    "            continue\n",
    "        \n",
    "        for func_name, func in functions.items():\n",
    "            stats[func_name][root] = func(embeddings, axis=0).tolist()\n",
    "        length = embeddings.shape[1]\n",
    "\n",
    "    filename = f'input/node_embeddings_{with_tags}_tags.json'\n",
    "    print(f\"Saving to {filename}, Embedding length: {length}\")\n",
    "\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(stats, f, indent=4)\n",
    "\n",
    "##############################\n",
    "for with_tags in ['no', 'with']:\n",
    "    make_node_clustering_input(with_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relation embedding algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data prep\n",
    "with open('../Method:Knowledge_Graphs/data/triplets_no_cutoff/graphs.json') as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "data = {}\n",
    "for root, triplets in results.items():\n",
    "    relations = []\n",
    "    for triplet in triplets:\n",
    "        relation = triplet[-1]\n",
    "        relations.append(relation)\n",
    "\n",
    "    data[root] = relations\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "data_emb = {}\n",
    "for root, relations in data.items():\n",
    "    relation_emb = []\n",
    "    for relation in relations:\n",
    "\n",
    "        rel_emb = nlp(relation).vector\n",
    "        relation_emb.append(rel_emb)\n",
    "\n",
    "    data_emb[root] = np.array(relation_emb)\n",
    "\n",
    "np.savez('data/relation_embeddings', **data_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_relation_clustering_input():\n",
    "    data_emb = np.load('data/relation_embeddings.npz')\n",
    "    company_embeddings = {}\n",
    "\n",
    "    functions = {\n",
    "        'min': np.min,\n",
    "        'max': np.max,\n",
    "        'mean': np.mean,\n",
    "        'median': np.median\n",
    "    }\n",
    "\n",
    "    stats = {func_name: {} for func_name in functions}\n",
    "\n",
    "    length = None\n",
    "\n",
    "    for root, embeddings in data_emb.items():\n",
    "        if embeddings.size == 0:\n",
    "            # print(f\"Warning: Company {root} has no embeddings.\")\n",
    "            continue\n",
    "        \n",
    "        for func_name, func in functions.items():\n",
    "            stats[func_name][root] = func(embeddings, axis=0).tolist()\n",
    "        length = embeddings.shape[1]\n",
    "    \n",
    "    filename = 'input/relation_embeddings.json'\n",
    "    print(f\"Saving to {filename}, Embedding length: {length}\")\n",
    "\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(stats, f, indent=4)\n",
    "    \n",
    "##############\n",
    "make_relation_clustering_input()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
