{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjacency Matrices for the Clustering Exercies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'helper_functions' from '/Users/tiril/Documents/IndividualProject/nuclear_repo/knowledge_graphs/helper_functions.py'>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import importlib\n",
    "\n",
    "import helper_functions as hf\n",
    "importlib.reload(hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_directory = 'data/triplets_no_cutoff'\n",
    "save_directory = 'graphs/triplets_no_cutoff'\n",
    "\n",
    "with open(base_directory + '/graphs.json', 'r') as file:\n",
    "    results = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "residence: 0\n",
      "country of origin: 1\n",
      "founded by: 2\n",
      "contains division: 3\n",
      "division: 4\n",
      "capital: 5\n",
      "industry: 6\n",
      "company: 7\n",
      "ethnicity: 8\n",
      "place of death: 9\n",
      "nationality: 10\n",
      "contains: 11\n",
      "company location: 12\n",
      "ethnic background: 13\n",
      "child: 14\n",
      "shareholder of: 15\n",
      "neighborhood: 16\n",
      "place of birth: 17\n"
     ]
    }
   ],
   "source": [
    "# Make relations dict\n",
    "relations = set()\n",
    "relations_dict = {}\n",
    "\n",
    "for name, triplets in results.items():\n",
    "    for triplet in triplets:\n",
    "        _, _, _, _, rel = triplet\n",
    "        relations.add(rel)\n",
    "\n",
    "relations = list(relations)\n",
    "\n",
    "for i in range(len((relations))):\n",
    "    relations_dict[relations[i]] = i\n",
    "\n",
    "for k, v in relations_dict.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce dimensionality of relations (keep granularity only for 'important' organisational relations)\n",
    "relations_dict = {\n",
    "\n",
    "    # Organisational\n",
    "    'division': 1,\n",
    "    'contains division': 1,\n",
    "    'contains': 2,\n",
    "    'shareholder of': 3,\n",
    "    'founded by': 4,\n",
    "    'company': 5,\n",
    "    'industry': 6,\n",
    "    'company location': 7,\n",
    "\n",
    "    # Other \n",
    "    'child': 0,\n",
    "    'place of death': 0,\n",
    "    'residence': 0,\n",
    "    'neighborhood': 0,\n",
    "    'capital': 0,\n",
    "    'ethnic background': 0,\n",
    "    'ethnicity': 0,\n",
    "    'nationality': 0,\n",
    "    'country of origin': 0,\n",
    "    'place of birth': 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formula for adjacency matrix creation\n",
    "def make_adj_matrices(results, relations_dict, max_depth=3, direction='bidirectional', include_entity_type=False):\n",
    "\n",
    "    adj_matrices = {}\n",
    "\n",
    "    # Make nodes dict\n",
    "    print(\"Creating nodes dictionary...\")\n",
    "    unique_nodes = set()\n",
    "    nodes_dict = {}\n",
    "    roots = []\n",
    "\n",
    "    for root, triplets in results.items():\n",
    "        root_node = (root, 'ORG')\n",
    "        try:\n",
    "            G = hf.make_graph(triplets)\n",
    "            G_pruned = hf.prune_graph_by_depth(G, root_node, max_depth, direction)\n",
    "            for node in G_pruned.nodes():\n",
    "                if include_entity_type:\n",
    "                    unique_nodes.add(f\"{node[0]}::{node[1]}\")\n",
    "                else:\n",
    "                    unique_nodes.add(node[0])\n",
    "            roots.append(root)\n",
    "        except nx.NodeNotFound:\n",
    "            print(f'Skipping for {root_node}')\n",
    "            continue\n",
    "        except hf.EmptyGraphError:\n",
    "            print(f'Skipping for {root_node}')\n",
    "\n",
    "    for i, node in enumerate(unique_nodes):\n",
    "        nodes_dict[node] = i\n",
    "    \n",
    "    print(f\"Nodes dictioary of length {len(nodes_dict)}\")\n",
    "    \n",
    "    # Next, create adjacency matrices\n",
    "    for root in roots:\n",
    "        triplets = results[root]\n",
    "        root_node = (root, 'ORG')\n",
    "        #print(f'Creating adjacency matrices for {root} (ORG)')\n",
    "\n",
    "        # 1. Create graph and prune it\n",
    "        G = hf.make_graph(triplets)\n",
    "        G_pruned = hf.prune_graph_by_depth(G, root_node, max_depth, direction)\n",
    "\n",
    "        D = len(set(relations_dict.values())) # Indicates number of adjacency matrices used\n",
    "        num_nodes = len(nodes_dict)\n",
    "\n",
    "        # 2. Initialise empty matrices\n",
    "        adj_matrix = np.zeros((num_nodes, num_nodes, D))\n",
    "\n",
    "        # 3. Get edges (aggregate in case of multiple)\n",
    "        for u, v, data in G_pruned.edges(data=True):\n",
    "            if include_entity_type:\n",
    "                head_with_ent = f\"{u[0]}::{u[1]}\"\n",
    "                tail_with_ent = f\"{v[0]}::{v[1]}\"\n",
    "            else:\n",
    "                head_with_ent = u[0]\n",
    "                tail_with_ent = v[0]\n",
    "\n",
    "            relation_name = data.get('relation')\n",
    "\n",
    "            relation_idx = relations_dict[relation_name]\n",
    "            u_idx = nodes_dict[head_with_ent]\n",
    "            v_idx = nodes_dict[tail_with_ent]\n",
    "\n",
    "            adj_matrix[u_idx, v_idx, relation_idx] = 1\n",
    "        \n",
    "        adj_matrices[root] = adj_matrix\n",
    "    \n",
    "    return adj_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating nodes dictionary...\n",
      "Skipping for ('Elysium', 'ORG')\n",
      "Skipping for ('HolosGen', 'ORG')\n",
      "Skipping for ('Hyperion Power', 'ORG')\n",
      "Skipping for ('StarCore Nuclear', 'ORG')\n",
      "Skipping for ('Terrestial', 'ORG')\n",
      "Nodes dictioary of length 1525\n",
      "Shape: (1525, 1525, 8)\n",
      "Saving to data/triplets_no_cutoff/adj_matrices_reduced_rel_dim_pruned_3_no_tags.npz\n"
     ]
    }
   ],
   "source": [
    "# Make nodes dict (depending on depth of prune and whether entity tags are included)\n",
    "base_directory = 'data/triplets_no_cutoff'\n",
    "with open(base_directory + '/graphs.json', 'r') as file:\n",
    "    results = json.load(file)\n",
    "\n",
    "prune_on = 3\n",
    "include_entity_type = False\n",
    "direction = 'bidirectional'\n",
    "\n",
    "adj_matrices = make_adj_matrices(results, relations_dict, prune_on, direction, include_entity_type=include_entity_type)\n",
    "print(f\"Shape: {adj_matrices['ARC'].shape}\")\n",
    "\n",
    "filepath = base_directory + f'/adj_matrices_reduced_rel_dim_pruned_{prune_on}_' + ('with' if include_entity_type else 'no') + '_tags.npz'\n",
    "print(f\"Saving to {filepath}\")\n",
    "np.savez_compressed(filepath, **adj_matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ARC 2590\n",
      "2 Babcock and Wilcox 2590\n",
      "3 Berkeley 2590\n",
      "4 BWX 2590\n",
      "5 Flibe 2590\n",
      "6 Framatome 2590\n",
      "7 GE Hitachi 2590\n",
      "8 General Atomics 2590\n",
      "9 Holtec International 2590\n",
      "10 Kairos Power 2590\n",
      "11 Moltex Energy 2590\n",
      "12 NANO Nuclear 2590\n",
      "13 NuScale 2590\n",
      "14 Oak Ridge National Laboratory 2590\n",
      "15 Oklo 2590\n",
      "16 TerraPower 2590\n",
      "17 ThorCon 2590\n",
      "18 Ultra Safe Nuclear Corporation 2590\n",
      "19 Westinghouse 2590\n",
      "20 X-Energy 2590\n"
     ]
    }
   ],
   "source": [
    "# Check that empty graphs aren't included (e.g. Elysium)\n",
    "for i, (k, v) in enumerate(adj_matrices.items()):\n",
    "    print(i+1, k, len(v))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
